{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98087ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4984 images belonging to 11 classes.\n",
      "Found 1241 images belonging to 11 classes.\n",
      "Found 3187 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "#DATA SETUP (Preprocessing & Augmentation)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Define Constants \n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 11  \n",
    "FOLDER_NAME = 'images.cv_jzk6llhf18tm3k0kyttxz'\n",
    "DATA_DIR = rf\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\Dataset\\{FOLDER_NAME}\\data\"\n",
    "# Initialize Data Generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2 # Reserve 20% for validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create Data Flow from Directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR,'train'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR,'train'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=42\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR,'test'),\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa7c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images.cv_jzk6llhf18tm3k0kyttxz']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\Dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24dd60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class indices: {'animal fish': 0, 'animal fish bass': 1, 'fish sea_food black_sea_sprat': 2, 'fish sea_food gilt_head_bream': 3, 'fish sea_food hourse_mackerel': 4, 'fish sea_food red_mullet': 5, 'fish sea_food red_sea_bream': 6, 'fish sea_food sea_bass': 7, 'fish sea_food shrimp': 8, 'fish sea_food striped_red_mullet': 9, 'fish sea_food trout': 10}\n",
      "Total classes: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Class indices:\", train_generator.class_indices)\n",
    "print(\"Total classes:\", train_generator.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada13f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting MobileNetV2 Model Training ---\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 1s/step - accuracy: 0.7264 - loss: 0.9037 - val_accuracy: 0.9490 - val_loss: 0.2799\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/155\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 422ms/step - accuracy: 0.9375 - loss: 0.4533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 164ms/step - accuracy: 0.9375 - loss: 0.4533 - val_accuracy: 0.9523 - val_loss: 0.2657\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 851ms/step - accuracy: 0.9287 - loss: 0.2813 - val_accuracy: 0.9704 - val_loss: 0.1442\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 161ms/step - accuracy: 0.8750 - loss: 0.3588 - val_accuracy: 0.9688 - val_loss: 0.1441\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 808ms/step - accuracy: 0.9546 - loss: 0.1769 - val_accuracy: 0.9737 - val_loss: 0.1092\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.1040 - val_accuracy: 0.9778 - val_loss: 0.1060\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 1s/step - accuracy: 0.9681 - loss: 0.1209 - val_accuracy: 0.9893 - val_loss: 0.0691\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 512ms/step - accuracy: 0.9375 - loss: 0.1806 - val_accuracy: 0.9819 - val_loss: 0.0759\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 3s/step - accuracy: 0.9729 - loss: 0.1012 - val_accuracy: 0.9827 - val_loss: 0.0682\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 573ms/step - accuracy: 0.9062 - loss: 0.1249 - val_accuracy: 0.9803 - val_loss: 0.0761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as: mobilenetv2_classifier_model.h5\n",
      "\n",
      "Final Test Set Evaluation\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.9820 - loss: 0.0674\n",
      "MobileNetV2 Final Test Loss: 0.0674\n",
      "MobileNetV2 Final Test Accuracy: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# MOBILENETV2 Transfer Learning Model Setup\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Assuming NUM_CLASSES and BATCH_SIZE are defined globally\n",
    "\n",
    "\n",
    "# Load Pre-trained Base Model (MobileNetV2)\n",
    "base_model_mobilenet = MobileNetV2( \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the Base Layers\n",
    "base_model_mobilenet.trainable = False \n",
    "\n",
    "x = base_model_mobilenet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model_mobilenet = Model(inputs=base_model_mobilenet.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "model_mobilenet.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\n--- Starting MobileNetV2 Model Training ---\")\n",
    "history_mobilenet = model_mobilenet.fit( \n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Trained Model\n",
    "MODEL_SAVE_PATH_MOBILENET = 'mobilenetv2_classifier_model.h5' \n",
    "model_mobilenet.save(MODEL_SAVE_PATH_MOBILENET)\n",
    "print(f\"\\nModel saved successfully as: {MODEL_SAVE_PATH_MOBILENET}\")\n",
    "\n",
    "\n",
    "#Final Test Set Evaluation\n",
    "print(\"\\nFinal Test Set Evaluation\")\n",
    "test_results_mobilenet = model_mobilenet.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# test_results will contain [loss, accuracy]\n",
    "test_loss_mobilenet = test_results_mobilenet[0]\n",
    "test_accuracy_mobilenet = test_results_mobilenet[1]\n",
    "\n",
    "print(f\"MobileNetV2 Final Test Loss: {test_loss_mobilenet:.4f}\")\n",
    "print(f\"MobileNetV2 Final Test Accuracy: {test_accuracy_mobilenet:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b65ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting VGG16 Model Training ---\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1783s\u001b[0m 12s/step - accuracy: 0.2668 - loss: 2.1133 - val_accuracy: 0.5477 - val_loss: 1.8049\n",
      "Epoch 2/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 2s/step - accuracy: 0.4062 - loss: 1.7605 - val_accuracy: 0.5312 - val_loss: 1.8009\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1333s\u001b[0m 9s/step - accuracy: 0.4471 - loss: 1.7234 - val_accuracy: 0.6431 - val_loss: 1.5396\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.6250 - loss: 1.6700 - val_accuracy: 0.6398 - val_loss: 1.5450\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1333s\u001b[0m 9s/step - accuracy: 0.5749 - loss: 1.4800 - val_accuracy: 0.7031 - val_loss: 1.3318\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 2s/step - accuracy: 0.7500 - loss: 1.2693 - val_accuracy: 0.6974 - val_loss: 1.3386\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1219s\u001b[0m 8s/step - accuracy: 0.6547 - loss: 1.2885 - val_accuracy: 0.7549 - val_loss: 1.1615\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - accuracy: 0.6875 - loss: 1.1707 - val_accuracy: 0.7664 - val_loss: 1.1436\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1195s\u001b[0m 8s/step - accuracy: 0.7086 - loss: 1.1380 - val_accuracy: 0.7648 - val_loss: 1.0384\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.9636 - val_accuracy: 0.7887 - val_loss: 1.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as: vgg16_classifier_model.h5\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout \n",
    "\n",
    "# Load Pre-trained Base Model (VGG16)\n",
    "base_model = VGG16( \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "base_model.trainable = False \n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model_vgg = Model(inputs=base_model.input, outputs=predictions) \n",
    "\n",
    "# Compile the Model\n",
    "model_vgg.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\n--- Starting VGG16 Model Training ---\")\n",
    "history_vgg = model_vgg.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Trained Model\n",
    "MODEL_SAVE_PATH_VGG = 'vgg16_classifier_model.h5' \n",
    "model_vgg.save(MODEL_SAVE_PATH_VGG)\n",
    "print(f\"\\nModel saved successfully as: {MODEL_SAVE_PATH_VGG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21555055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1us/step\n",
      "\n",
      "--- Starting ResNet50 Model Training ---\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 4s/step - accuracy: 0.1422 - loss: 2.4585 - val_accuracy: 0.1793 - val_loss: 2.2220\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/155\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:52\u001b[0m 2s/step - accuracy: 0.1875 - loss: 2.1725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 537ms/step - accuracy: 0.1875 - loss: 2.1725 - val_accuracy: 0.1793 - val_loss: 2.2221\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 3s/step - accuracy: 0.1799 - loss: 2.2803 - val_accuracy: 0.2245 - val_loss: 2.1838\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 515ms/step - accuracy: 0.2500 - loss: 2.1031 - val_accuracy: 0.2278 - val_loss: 2.1808\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 3s/step - accuracy: 0.2032 - loss: 2.1978 - val_accuracy: 0.1850 - val_loss: 2.1364\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 517ms/step - accuracy: 0.0625 - loss: 2.3533 - val_accuracy: 0.1850 - val_loss: 2.1362\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 3s/step - accuracy: 0.2197 - loss: 2.1569 - val_accuracy: 0.2368 - val_loss: 2.1026\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 633ms/step - accuracy: 0.2500 - loss: 2.1002 - val_accuracy: 0.2327 - val_loss: 2.1141\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 3s/step - accuracy: 0.2377 - loss: 2.1201 - val_accuracy: 0.2607 - val_loss: 2.0782\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 568ms/step - accuracy: 0.2500 - loss: 2.0980 - val_accuracy: 0.2763 - val_loss: 2.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as: resnet50_classifier_model.h5\n",
      "\n",
      "Final Test Set Evaluation\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 3s/step - accuracy: 0.2595 - loss: 2.0710\n",
      "ResNet50 Final Test Loss: 2.0710\n",
      "ResNet50 Final Test Accuracy: 0.2595\n"
     ]
    }
   ],
   "source": [
    "# RESNET50 Transfer Learning Model \n",
    "\n",
    "#Model Imports\n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# Load Pre-trained Base Model\n",
    "base_model_resnet = ResNet50( \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the Base Layers\n",
    "base_model_resnet.trainable = False \n",
    "\n",
    "\n",
    "# Add Custom Classification Head \n",
    "x = base_model_resnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model_resnet = Model(inputs=base_model_resnet.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "model_resnet.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\n--- Starting ResNet50 Model Training ---\")\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Trained Model\n",
    "MODEL_SAVE_PATH_RESNET = 'resnet50_classifier_model.h5' \n",
    "model_resnet.save(MODEL_SAVE_PATH_RESNET)\n",
    "print(f\"\\nModel saved successfully as: {MODEL_SAVE_PATH_RESNET}\")\n",
    "\n",
    "print(\"\\nFinal Test Set Evaluation\")\n",
    "test_results = model_resnet.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_loss_resnet = test_results[0]\n",
    "test_accuracy_resnet = test_results[1]\n",
    "\n",
    "print(f\"ResNet50 Final Test Loss: {test_loss_resnet:.4f}\")\n",
    "print(f\"ResNet50 Final Test Accuracy: {test_accuracy_resnet:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "\n",
      "Starting InceptionV3 Model Training\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 2s/step - accuracy: 0.6961 - loss: 0.9574 - val_accuracy: 0.9219 - val_loss: 0.3338\n",
      "Epoch 2/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 353ms/step - accuracy: 0.8750 - loss: 0.2730 - val_accuracy: 0.9194 - val_loss: 0.3336\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 2s/step - accuracy: 0.8835 - loss: 0.3619 - val_accuracy: 0.9391 - val_loss: 0.2324\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 352ms/step - accuracy: 0.7500 - loss: 0.6357 - val_accuracy: 0.9449 - val_loss: 0.2111\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 2s/step - accuracy: 0.9150 - loss: 0.2671 - val_accuracy: 0.9572 - val_loss: 0.1641\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 352ms/step - accuracy: 0.9062 - loss: 0.2277 - val_accuracy: 0.9556 - val_loss: 0.1626\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 2s/step - accuracy: 0.9307 - loss: 0.2112 - val_accuracy: 0.9696 - val_loss: 0.1206\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 349ms/step - accuracy: 0.9688 - loss: 0.1146 - val_accuracy: 0.9655 - val_loss: 0.1330\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 2s/step - accuracy: 0.9475 - loss: 0.1778 - val_accuracy: 0.9638 - val_loss: 0.1143\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 0.1378 - val_accuracy: 0.9663 - val_loss: 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as: inceptionv3_classifier_model.h5\n",
      "\n",
      "Final Test Set Evaluation\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.9732 - loss: 0.0957\n",
      "InceptionV3 Final Test Loss: 0.0957\n",
      "InceptionV3 Final Test Accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "# INCEPTIONV3 Transfer Learning Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#InceptionV3 standard input size \n",
    "base_model_inception = InceptionV3(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model_inception.trainable = False \n",
    "\n",
    "x = base_model_inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model_inception = Model(inputs=base_model_inception.input, outputs=predictions) \n",
    "\n",
    "# Compile the Model\n",
    "model_inception.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\nStarting InceptionV3 Model Training\")\n",
    "history_inception = model_inception.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Trained Model\n",
    "MODEL_SAVE_PATH_INCEPTION = 'inceptionv3_classifier_model.h5' \n",
    "model_inception.save(MODEL_SAVE_PATH_INCEPTION)\n",
    "print(f\"\\nModel saved successfully as: {MODEL_SAVE_PATH_INCEPTION}\")\n",
    "\n",
    "\n",
    "#'model_inception' is trained model and 'test_generator' is data generator\n",
    "\n",
    "print(\"\\nFinal Test Set Evaluation\")\n",
    "test_results_inception = model_inception.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# test_results will contain [loss, accuracy]\n",
    "test_loss_inception = test_results_inception[0]\n",
    "test_accuracy_inception = test_results_inception[1]\n",
    "\n",
    "print(f\"InceptionV3 Final Test Loss: {test_loss_inception:.4f}\")\n",
    "print(f\"InceptionV3 Final Test Accuracy: {test_accuracy_inception:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b20a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\n",
      "--- Starting EfficientNetB0 Model Training ---\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.1601 - loss: 2.3310 - val_accuracy: 0.1776 - val_loss: 2.3023\n",
      "Epoch 2/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.2188 - loss: 2.3002 - val_accuracy: 0.1776 - val_loss: 2.2993\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.1692 - loss: 2.3244 - val_accuracy: 0.1768 - val_loss: 2.2958\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.0625 - loss: 2.4094 - val_accuracy: 0.1735 - val_loss: 2.2982\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.1733 - loss: 2.3151 - val_accuracy: 0.1793 - val_loss: 2.2968\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.1562 - loss: 2.4006 - val_accuracy: 0.1760 - val_loss: 2.2996\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.1755 - loss: 2.3088 - val_accuracy: 0.1768 - val_loss: 2.2969\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.0312 - loss: 2.3939 - val_accuracy: 0.1760 - val_loss: 2.2976\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1000ms/step - accuracy: 0.1741 - loss: 2.3107 - val_accuracy: 0.1752 - val_loss: 2.3007\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.2188 - loss: 2.2689 - val_accuracy: 0.1768 - val_loss: 2.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as: efficientnetb0_classifier_model.h5\n",
      "\n",
      "Final Test Set Evaluation\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 657ms/step - accuracy: 0.1641 - loss: 2.3045\n",
      "EfficientNetB0 Final Test Loss: 2.3045\n",
      "EfficientNetB0 Final Test Accuracy: 0.1641\n"
     ]
    }
   ],
   "source": [
    "# EFFICIENTNETB0 Transfer Learning Model Setup\n",
    "from tensorflow.keras.applications import EfficientNetB0 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# Load Pre-trained Base Model (EfficientNetB0)\n",
    "base_model_effnet = EfficientNetB0( \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the Base Layers\n",
    "base_model_effnet.trainable = False \n",
    "\n",
    "\n",
    "# Add Custom Classification Head\n",
    "x = base_model_effnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model_effnet = Model(inputs=base_model_effnet.input, outputs=predictions) \n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "model_effnet.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "print(\"\\n--- Starting EfficientNetB0 Model Training ---\")\n",
    "history_effnet = model_effnet.fit( \n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Trained Model\n",
    "MODEL_SAVE_PATH_EFFNET = 'efficientnetb0_classifier_model.h5' \n",
    "model_effnet.save(MODEL_SAVE_PATH_EFFNET)\n",
    "print(f\"\\nModel saved successfully as: {MODEL_SAVE_PATH_EFFNET}\")\n",
    "\n",
    "\n",
    "print(\"\\nFinal Test Set Evaluation\")\n",
    "test_results_effnet = model_effnet.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# test_results will contain [loss, accuracy]\n",
    "test_loss_effnet = test_results_effnet[0]\n",
    "test_accuracy_effnet = test_results_effnet[1]\n",
    "\n",
    "print(f\"EfficientNetB0 Final Test Loss: {test_loss_effnet:.4f}\")\n",
    "print(f\"EfficientNetB0 Final Test Accuracy: {test_accuracy_effnet:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a99e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation on Test Set ---\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 981ms/step - accuracy: 0.9896 - loss: 0.0518\n",
      "Test Loss: 0.0518\n",
      "Test Accuracy: 0.9896\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 641ms/step\n",
      "\n",
      "--- Classification Report ---\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                     animal fish       0.98      1.00      0.99       520\n",
      "                animal fish bass       1.00      0.15      0.27        13\n",
      "   fish sea_food black_sea_sprat       1.00      0.98      0.99       298\n",
      "   fish sea_food gilt_head_bream       0.99      0.98      0.99       305\n",
      "   fish sea_food hourse_mackerel       1.00      0.99      1.00       286\n",
      "        fish sea_food red_mullet       0.99      1.00      0.99       291\n",
      "     fish sea_food red_sea_bream       0.98      1.00      0.99       273\n",
      "          fish sea_food sea_bass       0.98      1.00      0.99       327\n",
      "            fish sea_food shrimp       1.00      1.00      1.00       289\n",
      "fish sea_food striped_red_mullet       0.99      0.99      0.99       293\n",
      "             fish sea_food trout       1.00      1.00      1.00       292\n",
      "\n",
      "                        accuracy                           0.99      3187\n",
      "                       macro avg       0.99      0.92      0.93      3187\n",
      "                    weighted avg       0.99      0.99      0.99      3187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# MODEL EVALUATION\n",
    "print(\"\\n--- Model Evaluation on Test Set ---\")\n",
    "loss, accuracy = model_mobilenet.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate Classification Report and Confusion Matrix\n",
    "Y_pred = model_mobilenet.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74db92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f87642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation on Test Set (VGG16) ---\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m823s\u001b[0m 8s/step - accuracy: 0.7772 - loss: 0.9956\n",
      "VGG16 Test Loss: 0.9956\n",
      "VGG16 Test Accuracy: 0.7772\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m789s\u001b[0m 8s/step\n",
      "\n",
      "--- Classification Report ---\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                     animal fish       0.97      0.98      0.98       520\n",
      "                animal fish bass       0.00      0.00      0.00        13\n",
      "   fish sea_food black_sea_sprat       0.77      0.89      0.83       298\n",
      "   fish sea_food gilt_head_bream       0.94      0.33      0.49       305\n",
      "   fish sea_food hourse_mackerel       0.61      0.95      0.74       286\n",
      "        fish sea_food red_mullet       0.65      0.55      0.59       291\n",
      "     fish sea_food red_sea_bream       0.71      0.86      0.78       273\n",
      "          fish sea_food sea_bass       0.89      0.70      0.79       327\n",
      "            fish sea_food shrimp       0.72      0.99      0.83       289\n",
      "fish sea_food striped_red_mullet       0.63      0.49      0.55       293\n",
      "             fish sea_food trout       0.90      0.94      0.92       292\n",
      "\n",
      "                        accuracy                           0.78      3187\n",
      "                       macro avg       0.71      0.70      0.68      3187\n",
      "                    weighted avg       0.79      0.78      0.76      3187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model_vgg = load_model(r\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\vgg16_classifier_model.h5\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n--- Model Evaluation on Test Set (VGG16) ---\")\n",
    "loss, accuracy = model_vgg.evaluate(test_generator, verbose=1)\n",
    "print(f\"VGG16 Test Loss: {loss:.4f}\")\n",
    "print(f\"VGG16 Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "Y_pred = model_vgg.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ea695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation on Test Set (InceptionV3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.9733 - loss: 0.0952\n",
      "InceptionV3 Test Loss: 0.0952\n",
      "InceptionV3 Test Accuracy: 0.9733\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step\n",
      "\n",
      "--- Classification Report (InceptionV3) ---\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                     animal fish       0.97      0.99      0.98       520\n",
      "                animal fish bass       1.00      0.15      0.27        13\n",
      "   fish sea_food black_sea_sprat       0.98      0.99      0.99       298\n",
      "   fish sea_food gilt_head_bream       0.98      0.97      0.98       305\n",
      "   fish sea_food hourse_mackerel       0.96      0.98      0.97       286\n",
      "        fish sea_food red_mullet       0.99      0.95      0.97       291\n",
      "     fish sea_food red_sea_bream       0.99      0.98      0.99       273\n",
      "          fish sea_food sea_bass       0.96      0.96      0.96       327\n",
      "            fish sea_food shrimp       1.00      0.99      0.99       289\n",
      "fish sea_food striped_red_mullet       0.92      0.95      0.94       293\n",
      "             fish sea_food trout       0.99      0.99      0.99       292\n",
      "\n",
      "                        accuracy                           0.97      3187\n",
      "                       macro avg       0.98      0.90      0.91      3187\n",
      "                    weighted avg       0.97      0.97      0.97      3187\n",
      "\n",
      "\n",
      "--- Model Evaluation on Test Set (ResNet50) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.2611 - loss: 2.0704\n",
      "ResNet50 Test Loss: 2.0704\n",
      "ResNet50 Test Accuracy: 0.2611\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step\n",
      "\n",
      "--- Classification Report (ResNet50) ---\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                     animal fish       0.26      0.72      0.38       520\n",
      "                animal fish bass       0.00      0.00      0.00        13\n",
      "   fish sea_food black_sea_sprat       0.45      0.06      0.11       298\n",
      "   fish sea_food gilt_head_bream       0.00      0.00      0.00       305\n",
      "   fish sea_food hourse_mackerel       0.24      0.22      0.23       286\n",
      "        fish sea_food red_mullet       0.26      0.70      0.38       291\n",
      "     fish sea_food red_sea_bream       0.00      0.00      0.00       273\n",
      "          fish sea_food sea_bass       0.75      0.01      0.02       327\n",
      "            fish sea_food shrimp       0.00      0.00      0.00       289\n",
      "fish sea_food striped_red_mullet       0.46      0.13      0.21       293\n",
      "             fish sea_food trout       0.24      0.43      0.31       292\n",
      "\n",
      "                        accuracy                           0.26      3187\n",
      "                       macro avg       0.24      0.21      0.15      3187\n",
      "                    weighted avg       0.27      0.26      0.18      3187\n",
      "\n",
      "\n",
      "--- Model Evaluation on Test Set (EfficientNetB0) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 680ms/step - accuracy: 0.1632 - loss: 2.3045\n",
      "EfficientNetB0 Test Loss: 2.3045\n",
      "EfficientNetB0 Test Accuracy: 0.1632\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 690ms/step\n",
      "\n",
      "--- Classification Report (EfficientNetB0) ---\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                     animal fish       0.16      1.00      0.28       520\n",
      "                animal fish bass       0.00      0.00      0.00        13\n",
      "   fish sea_food black_sea_sprat       0.00      0.00      0.00       298\n",
      "   fish sea_food gilt_head_bream       0.00      0.00      0.00       305\n",
      "   fish sea_food hourse_mackerel       0.00      0.00      0.00       286\n",
      "        fish sea_food red_mullet       0.00      0.00      0.00       291\n",
      "     fish sea_food red_sea_bream       0.00      0.00      0.00       273\n",
      "          fish sea_food sea_bass       0.00      0.00      0.00       327\n",
      "            fish sea_food shrimp       0.00      0.00      0.00       289\n",
      "fish sea_food striped_red_mullet       0.00      0.00      0.00       293\n",
      "             fish sea_food trout       0.00      0.00      0.00       292\n",
      "\n",
      "                        accuracy                           0.16      3187\n",
      "                       macro avg       0.01      0.09      0.03      3187\n",
      "                    weighted avg       0.03      0.16      0.05      3187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\my_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Dictionary of model names and their respective file paths\n",
    "model_paths = {\n",
    "    \"InceptionV3\": r\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\inceptionv3_classifier_model.h5\",\n",
    "    \"ResNet50\": r\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\resnet50_classifier_model.h5\",\n",
    "    \"EfficientNetB0\": r\"C:\\Users\\sarit\\OneDrive\\Desktop\\multiclass_fish\\efficientnetb0_classifier_model.h5\"\n",
    "}\n",
    "\n",
    "# Loop through each model and evaluate\n",
    "for model_name, model_path in model_paths.items():\n",
    "    print(f\"\\nModel Evaluation on Test Set ({model_name}) \")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Evaluate performance\n",
    "    loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "    print(f\"{model_name} Test Loss: {loss:.4f}\")\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Generate predictions\n",
    "    Y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report ({model_name})\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
